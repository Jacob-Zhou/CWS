[Run]
is_test = 0
is_train = 1
threads = 8
inst_num_max = -1
max_bucket_num = 72
max_sent_length = 500
sent_batch_size = 10
char_batch_sizes = 500, 5000
min_word_len = 2, 2, 2
max_word_len = 8, 8, 8
with_bert = 1

[Test]
model_eval_num = 16

[Train]
path = "exp/zx.cd.bert/"
train_files = "data/zx/train.conll", 
dev_files = "data/zx/dev.conll", 
test_files = "data/zx/test.conll", 
train_extra_dictionarys = "data/dict/idioms", "data/dict/dict_1", "data/dict/ctb5.bpe.dict"
dev_extra_dictionarys = "data/dict/idioms", "data/dict/dict_1, data/dict/zx_dict.txt", "data/dict/zx.bpe.dict"
test_extra_dictionarys = "data/dict/idioms", "data/dict/dict_1, data/dict/zx_dict.txt", "data/dict/zx.bpe.dict"
bert_path = "data/bert-base-chinese.tar.gz"
bert_vocab = "data/bert-base-chinese-vocab.txt"
bert_config = "data/bert_config.json"
is_dictionary_exist = 1
train_max_eval_num = 1000
cutoff_freq = 1
patience = 5

[Network]
n_char_embed = 50
n_dict_embed = 5, 5, 5
n_bert_layers = 4
n_bert_embed = 100
embed_dropout = 0.5
n_lstm_hidden = 150
n_lstm_layers = 2
lstm_dropout = 0.2

[Optimizer]
lr = 1e-3
clip = 5.0

[Run]
is_test = 0
is_train = 1
threads = 8
inst_num_max = -1
max_bucket_num = 72
max_sent_length = 500
sent_batch_size = 10
char_batch_sizes = 500, 5000
min_word_len = 2
max_word_len = 8
with_bert = 1

[Test]
model_eval_num = 7

[Train]
path = "exp/zx/"
train_files = "data/zx/train.conll", 
dev_files = "data/zx/dev.conll", 
test_files = "data/zx/test.conll", 
extra_dictionarys = "data/dict/dict_1", "data/dict/zx_dict.txt", "data/dict/zx_sougou_dict.txt"
bert_path = "data/bert-base-chinese.tar.gz"
bert_vocab = "data/bert-base-chinese-vocab.txt"
bert_config = "data/bert_config.json"
is_dictionary_exist = 1
train_max_eval_num = 1000
cutoff_freq = 1
patience = 10

[Network]
n_char_embed = 50
n_dict_embed = 5
n_bert_layers = 4
n_bert_embed = 100
embed_dropout = 0.5
n_lstm_hidden = 150
n_lstm_layers = 2
lstm_dropout = 0.2

[Optimizer]
lr = 1e-3
clip = 5.0
